{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lập trình xử lý dữ liệu - Nhóm 7: Đánh đâu lỗ đó\n",
    "### Notebook Áp dụng học máy để phân loại cảm xúc bài viết\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thực hiện import các thư viện cần thiết gồm pandas, string, sklearn và demoji.\n",
    "\n",
    "pandas: Thư viện này được sử dụng để xử lý và phân tích dữ liệu, đặc biệt là khi làm việc với các cấu trúc dữ liệu như DataFrame, giúp dễ dàng quản lý và thao tác dữ liệu dạng bảng.\n",
    "\n",
    "string: Thư viện này cung cấp các chức năng hữu ích để thao tác với chuỗi ký tự trong Python, ví dụ như loại bỏ các dấu câu hoặc kiểm tra các ký tự cụ thể trong chuỗi.\n",
    "\n",
    "sklearn: Thư viện này hỗ trợ các công cụ máy học, bao gồm các mô hình phân loại như RandomForestClassifier. CountVectorizer từ sklearn được sử dụng để chuyển đổi văn bản thành các đặc trưng có thể sử dụng cho mô hình học máy. train_test_split giúp chia tập dữ liệu thành tập huấn luyện và tập kiểm tra.\n",
    "\n",
    "demoji: Thư viện này giúp xử lý và loại bỏ các emoji trong dữ liệu văn bản, giúp làm sạch dữ liệu trước khi phân tích.\n",
    "\n",
    "Trong phần phân tích này, ta sử dụng CountVectorizer để chuyển đổi nội dung bài viết thành các vector đặc trưng (sử dụng phương pháp \"bag of words\"). Sau đó, mô hình học máy RandomForestClassifier được áp dụng để phân loại các bài viết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import string \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import demoji \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_21616\\2299328559.py:1: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n",
      "  demoji.download_codes()\n"
     ]
    }
   ],
   "source": [
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postID</th>\n",
       "      <th>originalContent</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>totalLikes</th>\n",
       "      <th>totalReplies</th>\n",
       "      <th>replyToPostID</th>\n",
       "      <th>taggedSymbols</th>\n",
       "      <th>username</th>\n",
       "      <th>userid</th>\n",
       "      <th>totalImages</th>\n",
       "      <th>totalSymbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29104030</td>\n",
       "      <td>Vkl luôn</td>\n",
       "      <td>2024-11-06T21:39:23.267+07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'symb': '^DJI', 'price': 43496.43}]</td>\n",
       "      <td>Hoàng</td>\n",
       "      <td>5ededf24-12f7-41d9-b390-08ff631fc275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29104026</td>\n",
       "      <td>Đ.ịt cụ thằng Khải Trần hô VNI sập về 900 lần ...</td>\n",
       "      <td>2024-11-06T21:39:05.22+07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Datbg10</td>\n",
       "      <td>73778567-ec61-43eb-b3a0-b4a651b8bd3f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29104024</td>\n",
       "      <td>Tăng 1 phát bằng vn làm hai mấy năm :))</td>\n",
       "      <td>2024-11-06T21:39:04.077+07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'symb': '^DJI', 'price': 43506.86}]</td>\n",
       "      <td>Trung Tuyến</td>\n",
       "      <td>5d597f38-3b24-4f40-952c-2b3f9be8e7d5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29104021</td>\n",
       "      <td>Má đáng full tiền...đau</td>\n",
       "      <td>2024-11-06T21:38:52.277+07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'symb': 'VNINDEX', 'price': 1261.28}]</td>\n",
       "      <td>Duc Nguyen</td>\n",
       "      <td>225659c6-cf18-4e93-aa39-a294bae5b784</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29104019</td>\n",
       "      <td>Gap khủng long</td>\n",
       "      <td>2024-11-06T21:38:49.99+07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'symb': '^DJI', 'price': 43499.54}]</td>\n",
       "      <td>BINH NHI</td>\n",
       "      <td>da8ebfa2-9cd5-4dbf-84cd-9567f694f681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     postID                                    originalContent  \\\n",
       "0  29104030                                          Vkl luôn    \n",
       "1  29104026  Đ.ịt cụ thằng Khải Trần hô VNI sập về 900 lần ...   \n",
       "2  29104024            Tăng 1 phát bằng vn làm hai mấy năm :))   \n",
       "3  29104021                            Má đáng full tiền...đau   \n",
       "4  29104019                                     Gap khủng long   \n",
       "\n",
       "                            date link  sentiment  totalLikes  totalReplies  \\\n",
       "0  2024-11-06T21:39:23.267+07:00  NaN          0           1             0   \n",
       "1   2024-11-06T21:39:05.22+07:00  NaN          0           0             0   \n",
       "2  2024-11-06T21:39:04.077+07:00  NaN          0          12             2   \n",
       "3  2024-11-06T21:38:52.277+07:00  NaN          0           0             1   \n",
       "4   2024-11-06T21:38:49.99+07:00  NaN          0           2             0   \n",
       "\n",
       "   replyToPostID                            taggedSymbols     username  \\\n",
       "0            NaN    [{'symb': '^DJI', 'price': 43496.43}]        Hoàng   \n",
       "1            NaN                                       []      Datbg10   \n",
       "2            NaN    [{'symb': '^DJI', 'price': 43506.86}]  Trung Tuyến   \n",
       "3            NaN  [{'symb': 'VNINDEX', 'price': 1261.28}]   Duc Nguyen   \n",
       "4            NaN    [{'symb': '^DJI', 'price': 43499.54}]     BINH NHI   \n",
       "\n",
       "                                 userid  totalImages  totalSymbols  \n",
       "0  5ededf24-12f7-41d9-b390-08ff631fc275            0             1  \n",
       "1  73778567-ec61-43eb-b3a0-b4a651b8bd3f            0             0  \n",
       "2  5d597f38-3b24-4f40-952c-2b3f9be8e7d5            0             1  \n",
       "3  225659c6-cf18-4e93-aa39-a294bae5b784            1             1  \n",
       "4  da8ebfa2-9cd5-4dbf-84cd-9567f694f681            0             1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = pd.read_csv('cleaned_posts.csv')\n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi thực hiện đẩy dữ liệu từ file clean_posts.csv vào dataframe posts_df, ta chỉnh sưa cột sentiment từ 1, 0 và -1 lần lượt thành 'positive', 'neutral' và 'negative' tương ứng giúp dễ đọc và phân tích hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df['sentiment'] = posts_df['sentiment'].apply(lambda x: 'positive' if x == 1\n",
    "                                                        else 'negative' if x == -1 else 'neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta tải danh sách các từ dừng (stop words) từ một file CSV và chuyển chúng thành một tập hợp (set) để tối ưu hóa việc tra cứu. Hàm preprocess_text_optimized xử lý văn bản đầu vào bằng cách chuyển đổi thành chữ thường, loại bỏ dấu câu và các từ dừng, nhằm làm sạch dữ liệu trước khi phân tích. Kết quả là văn bản đã được chuẩn hóa, giúp các bước xử lý tiếp theo trở nên hiệu quả hơn.\n",
    "\n",
    "Stop words là các từ phổ biến, không mang nhiều ý nghĩa trong việc phân tích ngữ nghĩa của văn bản, như \"và\", \"hoặc\", \"của\", \"the\", \"is\", \"are\",... Những từ này thường không đóng góp nhiều trong việc phân loại hay tìm kiếm thông tin, vì vậy chúng được loại bỏ trong quá trình tiền xử lý dữ liệu. Trong đoạn code, các từ dừng được tải từ file CSV chứa danh sách các từ dừng tiếng Việt và sẽ được loại bỏ khỏi văn bản trong bước tiền xử lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = pd.read_csv('vietnamese-stopwords.csv')\n",
    "stop_words = stop_words['word'].tolist()\n",
    "stop_words = set(stop_words)\n",
    "\n",
    "def preprocess_text_optimized(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_21616\\1553288514.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  post_content['originalContent'] = post_content['originalContent'].apply(preprocess_text_optimized)\n"
     ]
    }
   ],
   "source": [
    "post_content = posts_df[['originalContent', 'sentiment']]\n",
    "\n",
    "post_content['originalContent'] = post_content['originalContent'].apply(preprocess_text_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cũng loại bỏ thêm các bài viết mà chỉ chứa link hoặc các bài viết spam. Đây là những nội dung rác không có tính đóng góp trong việc phân loại cảm xúc. \n",
    "\n",
    "Đồng thời ta cũng loại bỏ các emoji ra khỏi bài viết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove contents contains link only\n",
    "post_content = post_content[~post_content['originalContent'].str.match(r'^\\s*(http|https|www\\.).*$', na=False)]\n",
    "post_content.dropna(inplace=True)\n",
    "\n",
    "# remove all the emojis\n",
    "post_content['originalContent'] = post_content['originalContent'].apply(demoji.replace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalContent</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkl</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  originalContent sentiment\n",
       "0             vkl   neutral"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_content.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đoạn code trên tải danh sách các từ tục tĩu từ file Vietnamese_cursed_words.txt và chuyển chúng thành một tập hợp (set) để dễ dàng tra cứu. Hàm contains_cursed_words nhận vào một văn bản, chuyển văn bản thành chữ thường và tách thành các từ. Sau đó, nó đếm số lượng từ tục tĩu xuất hiện trong văn bản. Nếu có từ tục tĩu, hàm trả về giá trị 1 cùng với số lượng từ tục tĩu; nếu không, hàm trả về 0 và số lượng là 0. Quá trình này giúp phát hiện và đếm các từ tục tĩu trong văn bản, cũng cố cho độ chính xác của model học máy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursed_words = pd.read_csv('Vietnamese_cursed_words.txt')\n",
    "cursed_words = cursed_words['word'].tolist()\n",
    "cursed_words = set(cursed_words)\n",
    "\n",
    "def contains_cursed_words(text):\n",
    "    words = text.lower().split()\n",
    "    # return number of cursed words in the text\n",
    "    number_of_cursed_words = sum(1 for word in words if word in cursed_words)\n",
    "    if number_of_cursed_words > 0:\n",
    "        return 1, number_of_cursed_words\n",
    "    return 0, 0\n",
    "\n",
    "# test function\n",
    "contains_cursed_words('đệch đéo')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalContent</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>contains_cursed_words</th>\n",
       "      <th>numberOfCursedWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkl</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>địt cụ thằng khải trần hô vni sập 900 100</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 phát vn hai mấy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>má full tiềnđau</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gap khủng long</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272974</th>\n",
       "      <td>vc</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272975</th>\n",
       "      <td>chết dập chết dụi hic</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272976</th>\n",
       "      <td>múc rũ đỉnh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272977</th>\n",
       "      <td>đừng mong giá rẻ mấy ní đỏ ko mua xanh line</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272978</th>\n",
       "      <td>mua 600 cổ kia kìa mấy dời</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270357 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    originalContent sentiment  \\\n",
       "0                                               vkl   neutral   \n",
       "1         địt cụ thằng khải trần hô vni sập 900 100   neutral   \n",
       "2                                 1 phát vn hai mấy   neutral   \n",
       "3                                   má full tiềnđau   neutral   \n",
       "4                                    gap khủng long   neutral   \n",
       "...                                             ...       ...   \n",
       "272974                                           vc   neutral   \n",
       "272975                        chết dập chết dụi hic   neutral   \n",
       "272976                                  múc rũ đỉnh   neutral   \n",
       "272977  đừng mong giá rẻ mấy ní đỏ ko mua xanh line   neutral   \n",
       "272978                   mua 600 cổ kia kìa mấy dời   neutral   \n",
       "\n",
       "        contains_cursed_words  numberOfCursedWords  \n",
       "0                           1                    1  \n",
       "1                           1                    1  \n",
       "2                           0                    0  \n",
       "3                           0                    0  \n",
       "4                           0                    0  \n",
       "...                       ...                  ...  \n",
       "272974                      0                    0  \n",
       "272975                      1                    2  \n",
       "272976                      0                    0  \n",
       "272977                      0                    0  \n",
       "272978                      0                    0  \n",
       "\n",
       "[270357 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_content[['contains_cursed_words', 'numberOfCursedWords']] = post_content['originalContent'].apply(\n",
    "    contains_cursed_words\n",
    ").apply(pd.Series)\n",
    "\n",
    "post_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalContent</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>contains_cursed_words</th>\n",
       "      <th>numberOfCursedWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>vãi lồn</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ae đc xác thằng long quan official trôi dạt kh...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>đọc mãi báo đéo công văn quyết định thu hồi đé...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>vre xác 100 thoát vin xác 1 7 vol 35tr tham gi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>trump đắc cử tổng thống 47 mỹ chứng khoán việt...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       originalContent sentiment  \\\n",
       "80                                             vãi lồn   neutral   \n",
       "116  ae đc xác thằng long quan official trôi dạt kh...   neutral   \n",
       "193  đọc mãi báo đéo công văn quyết định thu hồi đé...  negative   \n",
       "344  vre xác 100 thoát vin xác 1 7 vol 35tr tham gi...   neutral   \n",
       "358  trump đắc cử tổng thống 47 mỹ chứng khoán việt...   neutral   \n",
       "\n",
       "     contains_cursed_words  numberOfCursedWords  \n",
       "80                       1                    2  \n",
       "116                      1                    2  \n",
       "193                      1                    4  \n",
       "344                      1                    3  \n",
       "358                      1                    2  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if function works correctly\n",
    "post_content[post_content['numberOfCursedWords'] > 1].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Training and testing model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cách 1: thực hiện việc xây dựng và đánh giá mô hình phân loại cảm xúc cho các bài viết. \n",
    "\n",
    "Đầu tiên, dữ liệu được chia thành hai phần: dữ liệu huấn luyện và dữ liệu kiểm tra, với các bài viết có cảm xúc không phải là \"neutral\" được dùng để huấn luyện mô hình. \n",
    "\n",
    "Văn bản của các bài viết được chuyển đổi thành đặc trưng số bằng cách sử dụng phương pháp TfidfVectorizer để tạo ma trận đặc trưng từ nội dung bài viết. \n",
    "\n",
    "Sau đó, các đặc trưng bổ sung như số lượng từ tục tĩu cũng được kết hợp vào ma trận đặc trưng này. Mô hình phân loại được huấn luyện với thuật toán RandomForestClassifier và được đánh giá bằng điểm số chính xác và báo cáo phân loại (classification report), cung cấp các thông số như độ chính xác, độ nhạy, và điểm F1 của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7582417582417582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.50      0.59      2654\n",
      "    positive       0.77      0.89      0.83      5081\n",
      "\n",
      "    accuracy                           0.76      7735\n",
      "   macro avg       0.74      0.70      0.71      7735\n",
      "weighted avg       0.75      0.76      0.75      7735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "train_content = post_content[post_content['sentiment'] != 'neutral']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_text = vectorizer.fit_transform(train_content['originalContent'])\n",
    "Y = train_content['sentiment']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_text, Y, test_size = 0.2, stratify = Y, random_state = 42)\n",
    "\n",
    "X = scipy.sparse.hstack([X_text, scipy.sparse.csr_matrix(train_content[['contains_cursed_words', 'numberOfCursedWords']].values)])\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.score(X_test, Y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "#### Kết quả phân loại cảm xúc\n",
    "\n",
    "Mô hình phân tích cảm xúc của bài viết đạt kết quả như sau:\n",
    "\n",
    "##### 1. **Độ chính xác (Accuracy)**\n",
    "\n",
    "- **Giải thích**: Độ chính xác là tỷ lệ bài viết được phân loại đúng trong tổng số bài viết.\n",
    "- **Công thức**: \n",
    "  $$\n",
    "  \\text{Accuracy} = \\frac{\\text{Số lượng phân loại đúng}}{\\text{Tổng số bài viết}}\n",
    "  $$\n",
    "- **Kết quả**: 0.76 (76%)\n",
    "  \n",
    "Mô hình có độ chính xác 76%, cho thấy mô hình có khả năng phân loại đúng tổng thể các bài viết trong tập kiểm tra.\n",
    "\n",
    "##### 2. **Độ chính xác (Precision)**\n",
    "\n",
    "- **Giải thích**: Độ chính xác đo lường tỷ lệ các bài viết thực sự thuộc lớp đó trong tất cả các bài viết được phân loại vào lớp đó.\n",
    "- **Công thức**: \n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Positive}}\n",
    "  $$\n",
    "- **Kết quả**:\n",
    "  - **Lớp \"negative\"**: 0.71 (71%)\n",
    "  - **Lớp \"positive\"**: 0.77 (77%)\n",
    "  \n",
    "Mô hình có độ chính xác khá cao cho lớp \"positive\" nhưng thấp hơn đối với lớp \"negative\", cho thấy mô hình ít phân loại sai với lớp \"positive\".\n",
    "\n",
    "##### 3. **Độ nhạy (Recall)**\n",
    "\n",
    "- **Giải thích**: Độ nhạy đo lường khả năng của mô hình trong việc phát hiện tất cả các bài viết thuộc lớp đó.\n",
    "- **Công thức**: \n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Negative}}\n",
    "  $$\n",
    "- **Kết quả**:\n",
    "  - **Lớp \"negative\"**: 0.50 (50%)\n",
    "  - **Lớp \"positive\"**: 0.89 (89%)\n",
    "\n",
    "Mô hình có độ nhạy tốt cho lớp \"positive\", nhưng đối với lớp \"negative\", độ nhạy thấp cho thấy mô hình chưa phát hiện được hết các bài viết tiêu cực.\n",
    "\n",
    "##### 4. **Điểm F1 (F1-score)**\n",
    "\n",
    "- **Giải thích**: Điểm F1 là chỉ số kết hợp giữa độ chính xác và độ nhạy, dùng để đánh giá hiệu suất tổng thể của mô hình.\n",
    "- **Công thức**: \n",
    "  $$\n",
    "  \\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$\n",
    "- **Kết quả**:\n",
    "  - **Lớp \"negative\"**: 0.59\n",
    "  - **Lớp \"positive\"**: 0.83\n",
    "  \n",
    "Điểm F1 của lớp \"positive\" cao hơn lớp \"negative\", cho thấy mô hình phân loại bài viết tích cực tốt hơn tiêu cực.\n",
    "\n",
    "##### 5. **Chỉ số tổng hợp**\n",
    "\n",
    "- **Macro avg**: Trung bình các chỉ số cho tất cả các lớp.\n",
    "  - **Precision**: 0.74\n",
    "  - **Recall**: 0.70\n",
    "  - **F1-score**: 0.71\n",
    "\n",
    "- **Weighted avg**: Trung bình có trọng số của các chỉ số, cân nhắc đến sự phân bổ lớp không đều.\n",
    "  - **F1-score**: 0.75\n",
    "\n",
    "---\n",
    "\n",
    "##### Nhận xét\n",
    "\n",
    "- Mô hình thể hiện hiệu quả tốt trong việc phân loại các bài viết có cảm xúc tích cực (positive) với độ chính xác và độ nhạy cao.\n",
    "- Tuy nhiên, mô hình gặp khó khăn trong việc nhận diện các bài viết tiêu cực (negative), với độ nhạy chỉ đạt 50%, cho thấy mô hình bỏ sót một phần lớn các bài viết tiêu cực.\n",
    "- Điểm F1 trung bình cho thấy mô hình có sự cân bằng giữa độ chính xác và độ nhạy, nhưng vẫn cần cải thiện khả năng nhận diện lớp tiêu cực để đạt được hiệu suất tốt hơn.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts need to classify: 233586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postID</th>\n",
       "      <th>originalContent</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>totalLikes</th>\n",
       "      <th>totalReplies</th>\n",
       "      <th>replyToPostID</th>\n",
       "      <th>taggedSymbols</th>\n",
       "      <th>username</th>\n",
       "      <th>userid</th>\n",
       "      <th>totalImages</th>\n",
       "      <th>totalSymbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29104030</td>\n",
       "      <td>Vkl luôn</td>\n",
       "      <td>2024-11-06T21:39:23.267+07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'symb': '^DJI', 'price': 43496.43}]</td>\n",
       "      <td>Hoàng</td>\n",
       "      <td>5ededf24-12f7-41d9-b390-08ff631fc275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     postID originalContent                           date link sentiment  \\\n",
       "0  29104030       Vkl luôn   2024-11-06T21:39:23.267+07:00  NaN  negative   \n",
       "\n",
       "   totalLikes  totalReplies  replyToPostID  \\\n",
       "0           1             0            NaN   \n",
       "\n",
       "                           taggedSymbols username  \\\n",
       "0  [{'symb': '^DJI', 'price': 43496.43}]    Hoàng   \n",
       "\n",
       "                                 userid  totalImages  totalSymbols  \n",
       "0  5ededf24-12f7-41d9-b390-08ff631fc275            0             1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_to_classify = posts_df.loc[posts_df['sentiment'] == 'neutral', 'originalContent']\n",
    "print(f\"Number of posts need to classify: {len(post_to_classify)}\")\n",
    "\n",
    "X_post = vectorizer.transform(post_to_classify)\n",
    "sentiment_predicted = clf.predict(X_post)\n",
    "\n",
    "new_post_df = posts_df.copy()\n",
    "\n",
    "new_post_df.loc[new_post_df['sentiment'] == 'neutral', 'sentiment'] = sentiment_predicted\n",
    "new_post_df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta áp dụng mô hình vừa huấn luyện để phân loại các bài viết trung tính(neutral) thành tích cực(positive) và tiêu cực(negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative posts (before) 13317\n",
      "Number of positive posts(before) 26076\n",
      "Number of negative posts (after) 59765\n",
      "Number of positive posts(after) 213214\n"
     ]
    }
   ],
   "source": [
    "print('Number of negative posts (before)', len(posts_df[posts_df['sentiment'] == 'negative']))\n",
    "print('Number of positive posts(before)', len(posts_df[posts_df['sentiment'] == 'positive']))\n",
    "print('Number of negative posts (after)', len(new_post_df[new_post_df['sentiment'] == 'negative']))\n",
    "print('Number of positive posts(after)', len(new_post_df[new_post_df['sentiment'] == 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiêu đạt độ chính xác tổng thể gần 76%, số lượng bài viết tích cực và tiêu cực sau khi được phân loại lại cho thấy sự chênh lệch quá lớn, số lượng bài viết tích cực trước chỉ gấp đôi nay đã gấp gần 4 lần số bài viết tiêu cực. Điều này cho thấy rõ hạn chế về cách tiếp cận và độ chính xác của mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Ta triển khai một cách tiếp cận mới nhằm cải thiện hiệu suất phân loại cảm xúc bằng cách cân bằng dữ liệu, sử dụng cả đặc trưng văn bản và các đặc trưng bổ sung (số lượng từ xấu và sự xuất hiện từ xấu). Các bước chính của mô hình này bao gồm:\n",
    "\n",
    "1. **Chuẩn bị dữ liệu**:\n",
    "   - Dữ liệu được chia thành hai phần: `train_content` (dùng để huấn luyện) và `test_content` (dùng để kiểm tra).\n",
    "   - Để xử lý vấn đề mất cân bằng nhãn giữa các bài viết có cảm xúc \"negative\" và \"positive\", các hàng có nhãn \"negative\" trong tập huấn luyện được nhân bản, giúp cân bằng số lượng mẫu giữa các lớp.\n",
    "\n",
    "2. **Vector hóa nội dung văn bản**:\n",
    "   - Văn bản được chuyển đổi thành biểu diễn số thông qua `TfidfVectorizer`, tạo ra các đặc trưng dạng sparse từ nội dung bài viết. \n",
    "   - Bộ vector hóa được áp dụng riêng cho tập huấn luyện và tập kiểm tra để đảm bảo tính độc lập của dữ liệu kiểm tra.\n",
    "\n",
    "3. **Kết hợp đặc trưng bổ sung**:\n",
    "   - Các đặc trưng bổ sung gồm số lượng từ không phù hợp (`numberOfCursedWords`) và cờ đánh dấu sự xuất hiện của từ không phù hợp (`contains_cursed_words`) được chuyển đổi thành ma trận thưa (`sparse matrix`).\n",
    "   - Văn bản vector hóa và các đặc trưng bổ sung được kết hợp để tạo ra ma trận đặc trưng đầu vào.\n",
    "\n",
    "4. **Chia tập huấn luyện và kiểm tra**:\n",
    "   - Tập huấn luyện tiếp tục được chia thành hai phần: tập huấn luyện thực tế (`X_train`) và tập xác thực (`X_val`) theo tỷ lệ 80-20. Việc này giúp đánh giá hiệu suất mô hình trên dữ liệu chưa thấy trước khi kiểm tra trên tập kiểm tra thực tế.\n",
    "\n",
    "5. **Huấn luyện mô hình**:\n",
    "   - Mô hình `RandomForestClassifier` được sử dụng để huấn luyện trên tập dữ liệu huấn luyện đã chuẩn bị.\n",
    "\n",
    "6. **Đánh giá mô hình**:\n",
    "   - Hiệu suất mô hình được đánh giá trên cả tập xác thực (`X_val`) và tập kiểm tra (`X_test`) bằng cách sử dụng các chỉ số như `precision`, `recall`, `f1-score` và `accuracy`. Báo cáo phân loại (`classification_report`) cung cấp thông tin chi tiết về hiệu quả phân loại từng lớp.\n",
    "\n",
    "---\n",
    "\n",
    "#### Nhận xét về cách tiếp cận mới\n",
    "\n",
    "- **Cân bằng dữ liệu**: Việc nhân bản các bài viết có nhãn \"negative\" là một cải tiến quan trọng, giúp giải quyết vấn đề mất cân bằng dữ liệu và đảm bảo mô hình không bị thiên vị đối với lớp \"positive\".\n",
    "- **Tích hợp đặc trưng bổ sung**: Kết hợp các đặc trưng bổ sung từ nội dung bài viết (như số lượng từ không phù hợp) với đặc trưng văn bản từ `TfidfVectorizer` giúp mô hình tận dụng tốt hơn thông tin phi ngôn ngữ để cải thiện hiệu quả phân loại.\n",
    "- **Đánh giá hiệu suất**: Việc đánh giá trên cả tập xác thực và tập kiểm tra giúp kiểm chứng khả năng tổng quát hóa của mô hình, đảm bảo rằng nó hoạt động tốt trên dữ liệu chưa thấy trước.\n",
    "\n",
    "---\n",
    "\n",
    "#### So sánh với cách tiếp cận cũ\n",
    "\n",
    "So với cách tiếp cận trước đó:\n",
    "- **Cải thiện cân bằng mẫu**: Việc nhân bản dữ liệu tiêu cực là một điểm mới, cải thiện khả năng học của mô hình với lớp thiểu số.\n",
    "- **Tách biệt tập kiểm tra**: Phương pháp này tách riêng tập kiểm tra ngay từ đầu, tránh việc dữ liệu kiểm tra bị ảnh hưởng bởi quá trình huấn luyện và xác thực, đảm bảo đánh giá mô hình khách quan hơn.\n",
    "\n",
    "Với cách tiếp cận này, mô hình có tiềm năng đạt được kết quả tốt hơn nhờ sử dụng đầy đủ thông tin trong dữ liệu và giải quyết vấn đề mất cân bằng lớp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.93      0.87      5308\n",
      "    positive       0.91      0.79      0.85      5081\n",
      "\n",
      "    accuracy                           0.86     10389\n",
      "   macro avg       0.87      0.86      0.86     10389\n",
      "weighted avg       0.87      0.86      0.86     10389\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93     13268\n",
      "    positive       0.99      0.94      0.96     25405\n",
      "\n",
      "    accuracy                           0.95     38673\n",
      "   macro avg       0.94      0.96      0.95     38673\n",
      "weighted avg       0.96      0.95      0.95     38673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Separate train and test content\n",
    "train_content = post_content[post_content['sentiment'] != 'neutral']\n",
    "test_content = post_content[post_content['sentiment'] != 'neutral']\n",
    "\n",
    "# Duplicate rows that sentiment is negative to balance sample size\n",
    "train_content = pd.concat([train_content, train_content[train_content['sentiment'] == 'negative']])\n",
    "\n",
    "# Vectorize the text content\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_text_train = vectorizer.fit_transform(train_content['originalContent'])\n",
    "X_text_test = vectorizer.transform(test_content['originalContent'])\n",
    "\n",
    "# Additional features\n",
    "X_train_additional = scipy.sparse.csr_matrix(train_content[['contains_cursed_words', 'numberOfCursedWords']].values)\n",
    "X_test_additional = scipy.sparse.csr_matrix(test_content[['contains_cursed_words', 'numberOfCursedWords']].values)\n",
    "\n",
    "# Combine text features and additional features\n",
    "X_train = scipy.sparse.hstack([X_text_train, X_train_additional])\n",
    "X_test = scipy.sparse.hstack([X_text_test, X_test_additional])\n",
    "\n",
    "# Target labels\n",
    "Y_train = train_content['sentiment']\n",
    "Y_test = test_content['sentiment']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=42)\n",
    "\n",
    "# Model training\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred = clf.predict(X_val)\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(Y_val, y_pred))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(Y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nhận xét kết quả mô hình\n",
    "\n",
    "##### 1. **Báo cáo trên tập xác thực (Validation Classification Report)**:\n",
    "   - **Độ chính xác (Accuracy):** Mô hình đạt **86%**, cho thấy hiệu suất khá tốt trong việc dự đoán cảm xúc trên tập dữ liệu xác thực.\n",
    "   - **Precision và Recall:**\n",
    "     - **Negative:** \n",
    "       - Precision: 82%, nghĩa là trong tất cả các dự đoán \"negative\", 82% là chính xác.\n",
    "       - Recall: 93%, cho thấy mô hình đã phát hiện hầu hết các bài viết thuộc lớp \"negative\".\n",
    "     - **Positive:** \n",
    "       - Precision: 91%, mô hình rất chính xác trong việc dự đoán \"positive\".\n",
    "       - Recall: 79%, thấp hơn \"negative\", cho thấy mô hình bỏ sót một số bài viết thuộc lớp \"positive\".\n",
    "   - **F1-Score:** Trung bình hài hòa của Precision và Recall, lần lượt là **87%** cho \"negative\" và **85%** cho \"positive\". Kết quả này phản ánh sự cân đối tương đối tốt giữa hai chỉ số trên.\n",
    "   - **Nhận xét:** Hiệu suất trên tập xác thực cho thấy mô hình học tốt hơn với lớp \"negative\" so với \"positive\", thể hiện qua Recall cao hơn cho \"negative\". Tuy nhiên, sự chênh lệch này có thể dẫn đến một chút thiên vị.\n",
    "\n",
    "##### 2. **Báo cáo trên tập kiểm tra (Test Classification Report)**:\n",
    "   - **Độ chính xác (Accuracy):** Mô hình đạt **95%**, cải thiện đáng kể so với tập xác thực, chứng tỏ mô hình tổng quát hóa tốt khi áp dụng trên dữ liệu chưa thấy trước.\n",
    "   - **Precision và Recall:**\n",
    "     - **Negative:**\n",
    "       - Precision: 89%, nghĩa là trong các dự đoán \"negative\", 89% là đúng.\n",
    "       - Recall: 98%, rất cao, chứng tỏ mô hình nhận diện hầu hết các bài viết \"negative\".\n",
    "     - **Positive:**\n",
    "       - Precision: 99%, cho thấy gần như tất cả các dự đoán \"positive\" đều chính xác.\n",
    "       - Recall: 94%, hơi thấp hơn một chút, nhưng vẫn rất tốt.\n",
    "   - **F1-Score:** Lớp \"positive\" đạt **96%**, cao hơn lớp \"negative\" (**93%**), phản ánh sự cân đối tốt hơn trên tập kiểm tra.\n",
    "   - **Nhận xét:** Kết quả trên tập kiểm tra rất ấn tượng, với độ chính xác và các chỉ số khác đều cao. Điều này có thể được giải thích bởi việc mô hình đã được huấn luyện trên một tập dữ liệu được cân bằng tốt hơn và tích hợp các đặc trưng bổ sung.\n",
    "\n",
    "---\n",
    "\n",
    "##### **So sánh giữa tập xác thực và tập kiểm tra**:\n",
    "   - **Độ chính xác:** Tăng từ **86%** trên tập xác thực lên **95%** trên tập kiểm tra, cho thấy sự cải thiện rõ rệt trong dự đoán.\n",
    "   - **Hiệu suất từng lớp:** \n",
    "     - Lớp \"negative\" cải thiện về Precision và Recall trên tập kiểm tra.\n",
    "     - Lớp \"positive\" cũng cho thấy Precision và F1-score rất cao, nhưng Recall giảm nhẹ so với tập xác thực.\n",
    "   - **Nhận xét tổng thể:** Mặc dù có sự khác biệt giữa các chỉ số trên tập xác thực và kiểm tra, mô hình tổng quát hóa tốt và có khả năng phân loại chính xác cảm xúc của các bài viết, đặc biệt trên tập kiểm tra lớn hơn.\n",
    "\n",
    "---\n",
    "\n",
    "##### Kết luận\n",
    "Mô hình hoạt động hiệu quả trên cả hai tập dữ liệu. Kết quả trên tập kiểm tra đặc biệt tốt, đạt độ chính xác cao và cân đối tốt giữa hai lớp cảm xúc. Với Recall cao cho lớp \"negative\" và Precision vượt trội cho lớp \"positive\", mô hình có tiềm năng áp dụng thực tế trong việc phân loại cảm xúc. Tuy nhiên, cần lưu ý rằng mô hình có thể bỏ sót một số bài viết thuộc lớp \"positive\" trên tập xác thực, và điều này cần được cải thiện thêm thông qua các phương pháp như tinh chỉnh siêu tham số hoặc bổ sung dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts need to classify: 231684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalContent</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>contains_cursed_words</th>\n",
       "      <th>numberOfCursedWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkl</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>địt cụ thằng khải trần hô vni sập 900 100</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 phát vn hai mấy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>má full tiềnđau</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gap khủng long</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             originalContent sentiment  contains_cursed_words  \\\n",
       "0                                        vkl  negative                      1   \n",
       "1  địt cụ thằng khải trần hô vni sập 900 100  negative                      1   \n",
       "2                          1 phát vn hai mấy  positive                      0   \n",
       "3                            má full tiềnđau  negative                      0   \n",
       "4                             gap khủng long  positive                      0   \n",
       "\n",
       "   numberOfCursedWords  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the model to classify the sentiment of neutral posts\n",
    "post_to_classify = post_content.loc[post_content['sentiment'] == 'neutral', ['originalContent', 'contains_cursed_words', 'numberOfCursedWords']]\n",
    "print(f\"Number of posts need to classify: {len(post_to_classify)}\")\n",
    "\n",
    "# Vectorize the text content\n",
    "X_post_text = vectorizer.transform(post_to_classify['originalContent'])\n",
    "\n",
    "# Convert the additional features to a sparse matrix\n",
    "X_post_additional = scipy.sparse.csr_matrix(post_to_classify[['contains_cursed_words', 'numberOfCursedWords']].values)\n",
    "\n",
    "# Combine the text features and additional features\n",
    "X_post = scipy.sparse.hstack([X_post_text, X_post_additional])\n",
    "\n",
    "# Predict sentiment using the trained classifier\n",
    "sentiment_predicted = clf.predict(X_post)\n",
    "\n",
    "# Copy the original DataFrame to add the predicted sentiments\n",
    "new_post_df = post_content.copy()\n",
    "\n",
    "# Update the 'sentiment' column for the neutral posts with the predicted values\n",
    "new_post_df.loc[new_post_df['sentiment'] == 'neutral', 'sentiment'] = sentiment_predicted\n",
    "\n",
    "# Display the updated DataFrame\n",
    "new_post_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta áp dụng mô hình phân loại cảm xúc đã huấn luyện để xác định cảm xúc cho các bài viết có nhãn \"neutral\". \n",
    "\n",
    "Trước tiên, tách các bài viết trung tính và vector hóa nội dung văn bản sử dụng TfidfVectorizer. Chuyển đổi thành ma trận thưa các đặc trưng bổ sung (số lượng từ không phù hợp và sự xuất hiện của từ không phù hợp). \n",
    "\n",
    "Các đặc trưng văn bản và bổ sung sau đó được kết hợp và dùng làm đầu vào cho mô hình để dự đoán cảm xúc. \n",
    "\n",
    "Cuối cùng, cột sentiment trong DataFrame gốc được cập nhật bằng các dự đoán này, giúp phân loại các bài viết trung tính thành tích cực hoặc tiêu cực."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative posts (before) 13317\n",
      "Number of positive posts(before) 26076\n",
      "Number of negative posts (after) 123447\n",
      "Number of positive posts(after) 146910\n"
     ]
    }
   ],
   "source": [
    "# check the number of negative and positive posts before and after\n",
    "print('Number of negative posts (before)', len(posts_df[posts_df['sentiment'] == 'negative']))\n",
    "print('Number of positive posts(before)', len(posts_df[posts_df['sentiment'] == 'positive']))\n",
    "print('Number of negative posts (after)', len(new_post_df[new_post_df['sentiment'] == 'negative']))\n",
    "print('Number of positive posts(after)', len(new_post_df[new_post_df['sentiment'] == 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So với phương pháp trước, số lượng bài viết thuộc hai lớp \"tiêu cực\" và \"tích cực\" hiện đã được cân bằng tốt hơn, với sự chênh lệch ở mức hợp lý(140910 với 123447). Kết quả này khẳng định rằng việc áp dụng kỹ thuật nhân đôi số lượng bài viết tiêu cực để cân bằng dữ liệu trong quá trình huấn luyện là một quyết định phù hợp, giúp mô hình học tốt hơn và giảm thiểu khả năng thiên vị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalContent</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>contains_cursed_words</th>\n",
       "      <th>numberOfCursedWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkl</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>địt cụ thằng khải trần hô vni sập 900 100</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 phát vn hai mấy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>má full tiềnđau</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gap khủng long</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             originalContent sentiment  contains_cursed_words  \\\n",
       "0                                        vkl  negative                      1   \n",
       "1  địt cụ thằng khải trần hô vni sập 900 100  negative                      1   \n",
       "2                          1 phát vn hai mấy  positive                      0   \n",
       "3                            má full tiềnđau  negative                      0   \n",
       "4                             gap khủng long  positive                      0   \n",
       "\n",
       "   numberOfCursedWords  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_post_df.to_csv('new_posts_df.csv', index=False)\n",
    "new_post_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
